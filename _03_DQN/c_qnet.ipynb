{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b4c16c-800f-4220-a277-d19f078352cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH VERSION: 2.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"TORCH VERSION:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc71b69-5a10-47c7-8bbe-311737822639",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.path.dirname(\"./\")\n",
    "PROJECT_HOME = os.path.abspath(\"../\")\n",
    "if PROJECT_HOME not in sys.path:\n",
    "    sys.path.append(PROJECT_HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c97dec-0bd7-4e87-9602-9fcf21eb283d",
   "metadata": {},
   "source": [
    "### setting path\n",
    "- current_path : relative path -> ./\n",
    "- project_home : relative path -> ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a92574fc-779c-4616-be52-df6db886f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(PROJECT_HOME, \"_03_DQN\", \"models\")\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae72fd-75e8-4c34-abdd-88adc5f6ee8a",
   "metadata": {},
   "source": [
    "### Setting model path\n",
    "- model_dir : ../_03_DQN/models -> ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadd6225-d98a-41fd-8c41-807360500bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd6419-fcc3-4771-802f-96de24cae27f",
   "metadata": {},
   "source": [
    "### Setting using device\n",
    "- device : if you have cuda gpu torch device is cuda else using cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b1b15f-0a0a-40fc-bfad-8bd2ef47d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self, n_features=4, n_actions=2):\n",
    "        super(QNet, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(n_features, 128)  # fully connected\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, n_actions)\n",
    "        self.to(DEVICE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32, device=DEVICE)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def get_action(self, obs, epsilon=0.1):\n",
    "        # random.random(): 0.0과 1.0사이의 임의의 값을 반환\n",
    "        if random.random() < epsilon:\n",
    "            action = random.randrange(0, self.n_actions)\n",
    "        else:\n",
    "            q_values = self.forward(obs)\n",
    "            action = torch.argmax(q_values, dim=-1)\n",
    "            action = action.item()\n",
    "        return action  # argmax: 가장 큰 값에 대응되는 인덱스 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a8d002-93a1-463a-9974-680be2812d9e",
   "metadata": {},
   "source": [
    "### Q-Net\n",
    "This network is fully connected network(fcn)\n",
    "#### Layer Info\n",
    "- input layer : in(4) -> out(128)\n",
    "    - using activation function relu\n",
    "- hidden layer : int(128) -> out(128)\n",
    "    - using activation function relu\n",
    "- output layer : int(128) -> out(2)\n",
    "#### get_action function\n",
    "this function using epsilon_greedy\n",
    "- if get random value 0~1 is smaller than epsilon, return random action\n",
    "- else return greedy action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f4c55a-5ff3-4bfa-b14d-14b43f56514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = collections.namedtuple(\n",
    "    typename='Transition',\n",
    "    field_names=['observation', 'action', 'next_observation', 'reward', 'done']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04d8a8-929c-4ffa-9480-454936ff606b",
   "metadata": {},
   "source": [
    "- Transition : ReplayBuffer value type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4706630-36e1-4ea8-b170-11e18a65914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = collections.deque(maxlen=capacity)\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    def append(self, transition: Transition) -> None:\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.buffer.pop()\n",
    "\n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        # Get random index\n",
    "        indices = np.random.choice(len(self.buffer), size=batch_size, replace=False)\n",
    "        # Sample\n",
    "        observations, actions, next_observations, rewards, dones = zip(*[self.buffer[idx] for idx in indices])\n",
    "\n",
    "        # Convert to ndarray for speed up cuda\n",
    "        observations = np.array(observations)\n",
    "        next_observations = np.array(next_observations)\n",
    "        # observations.shape, next_observations.shape: (32, 4), (32, 4)\n",
    "\n",
    "        actions = np.array(actions)\n",
    "        actions = np.expand_dims(actions, axis=-1) if actions.ndim == 1 else actions\n",
    "        rewards = np.array(rewards)\n",
    "        rewards = np.expand_dims(rewards, axis=-1) if rewards.ndim == 1 else rewards\n",
    "        dones = np.array(dones, dtype=bool)\n",
    "        # actions.shape, rewards.shape, dones.shape: (32, 1) (32, 1) (32,)\n",
    "\n",
    "        # Convert to tensor\n",
    "        observations = torch.tensor(observations, dtype=torch.float32, device=DEVICE)\n",
    "        actions = torch.tensor(actions, dtype=torch.int64, device=DEVICE)\n",
    "        next_observations = torch.tensor(next_observations, dtype=torch.float32, device=DEVICE)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32, device=DEVICE)\n",
    "        dones = torch.tensor(dones, dtype=torch.bool, device=DEVICE)\n",
    "\n",
    "        return observations, actions, next_observations, rewards, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892679c-24dc-426b-80ad-9af49a82335b",
   "metadata": {},
   "source": [
    "### ReplayBuffer\n",
    "This class used to minibatch SGD.  \n",
    "Buffer has episode step info.  \n",
    "when do gradient decent, return batch size random step info.  \n",
    "If current buffer size is equal buffer capacity, pop the oldest data and append new data.\n",
    "#### Why have to use minibatch SGD?  \n",
    "when don't use minibatch SGD, can cause state correlation problem.  \n",
    "Therefore, use minibatch SGD.\n",
    "#### What is minibatch SGD?\n",
    "minibatch SGD is when given the state of batch size, selecte some of random state.\n",
    "\n",
    "\n",
    "*별첨*  \n",
    "state correlation : 상태가 너무 가까운 것에만 최적화 하게 됨 즉 local minimum에서 빠져 나올 수 없음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympic",
   "language": "python",
   "name": "olympic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
