{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c366cd-847f-4f5e-ba24-8595677f7fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309b9b9c-8dd9-4efe-ae84-6e61d77308f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a2cef5-b7a9-484b-8b55-4220c6f5debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitionOlympicsEnvWrapper(gym.Wrapper):\n",
    "    metadata = {}\n",
    "\n",
    "    def __init__(self, env, agent=None, args=None):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.args = args\n",
    "        assert self.args\n",
    "\n",
    "        self.controlled_agent_index = args.controlled_agent_index\n",
    "\n",
    "        self.frame_stack = args.frame_stack\n",
    "        assert self.frame_stack > 0 or isinstance(self.frame_stack, int)\n",
    "        self.frames_controlled = deque([], maxlen=self.frame_stack)\n",
    "        self.frames_opponent = deque([], maxlen=self.frame_stack)\n",
    "\n",
    "        self.sub_game = args.env_name\n",
    "        self.device = args.device\n",
    "\n",
    "        self.episode_steps = 0\n",
    "        self.total_steps = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.episode_steps = 0\n",
    "        observation = self.env.reset()\n",
    "\n",
    "        observation_opponent_agent = np.expand_dims(\n",
    "            observation[1 - self.controlled_agent_index]['obs']['agent_obs'], axis=0\n",
    "        )\n",
    "        observation_controlled_agent = np.expand_dims(\n",
    "            observation[self.controlled_agent_index]['obs']['agent_obs'], axis=0\n",
    "        )\n",
    "\n",
    "        observation_opponent_agent = self.frame_stacking(self.frames_opponent, observation_opponent_agent)\n",
    "        observation_controlled_agent = self.frame_stacking(self.frames_controlled, observation_controlled_agent)\n",
    "\n",
    "        return [observation_controlled_agent], None    \n",
    "\n",
    "    def step(self, action_controlled):\n",
    "        # if is_evaluate true -> do game using agent, no train\n",
    "        if self.args.render_over_train or self.args.is_evaluate:\n",
    "            self.render()\n",
    "\n",
    "        self.episode_steps += 1\n",
    "        self.total_steps += 1\n",
    "\n",
    "        action_controlled = self.get_scaled_action(action_controlled)\n",
    "        action_opponent = self.get_opponent_action()\n",
    "\n",
    "        action_controlled = np.expand_dims(action_controlled, axis=1)\n",
    "        action_opponent = np.expand_dims(action_opponent, axis=1)\n",
    "\n",
    "        action = [action_opponent, action_controlled] if self.args.controlled_agent_index == 1 else [action_controlled, action_opponent]\n",
    "\n",
    "        next_observation, reward, done, info_before, info_after = self.env.step(action)\n",
    "\n",
    "        next_observation_opponent_agent = np.expand_dims(\n",
    "            next_observation[1 - self.controlled_agent_index]['obs']['agent_obs'], axis=0)\n",
    "        next_observation_controlled_agent = np.expand_dims(\n",
    "            next_observation[self.controlled_agent_index]['obs']['agent_obs'], axis=0\n",
    "        )\n",
    "\n",
    "        self.frames_opponent.append(next_observation_opponent_agent)\n",
    "        next_observation_opponent_agent = self._transform_observation(self.frames_opponent)\n",
    "\n",
    "        self.frames_controlled.append(next_observation_controlled_agent)\n",
    "        next_observation_controlled_agent = self._transform_observation(self.frames_controlled)\n",
    "\n",
    "        reward_controlled = reward[self.controlled_agent_index]\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return [next_observation_controlled_agent], reward_controlled, done, False, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        self.env.env_core.render()\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def get_opponent_action(self):\n",
    "        force = random.uniform(-100, 200)\n",
    "        angle = random.uniform(-30, 30)\n",
    "        opponent_scaled_actions = np.asarray([force, angle])\n",
    "\n",
    "        return opponent_scaled_actions\n",
    "\n",
    "    # 주어진 action을 force : -100~100, angle : -30~30으로 변경 -> force를 -100~200으로 변화 시킬 필요 있어 보임  추후 변경 요망\n",
    "    def get_scaled_action(self, action):\n",
    "        clipped_action = np.clip(action, -1.0, 1.0)\n",
    "\n",
    "        scaled_action_0 = -100 + (clipped_action[0] + 1) / 2 * (200 - (-100))\n",
    "        scaled_action_1 = -30 + (clipped_action[1] + 1) / 2 * (30 - (-30))\n",
    "\n",
    "        return numpy.asarray([scaled_action_0, scaled_action_1])\n",
    "\n",
    "    def frame_stacking(self, deque, obs):\n",
    "        for _ in range(self.frame_stack):\n",
    "            deque.append(obs)\n",
    "        obs = self._transform_observation(deque)\n",
    "        return obs\n",
    "\n",
    "    def _transform_observation(self, frames):\n",
    "        assert len(frames) == self.frame_stack\n",
    "        obs = np.concatenate(list(frames), axis=0)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff8217-a638-4e35-8235-f396b056d14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympic",
   "language": "python",
   "name": "olympic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
